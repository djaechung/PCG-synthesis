{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm","authorship_tag":"ABX9TyNjc+r74KlOnxv5VsLfVWFO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"mSnJjJe7ohi7","executionInfo":{"status":"ok","timestamp":1701890773657,"user_tz":300,"elapsed":2,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os, sys, errno\n","import glob\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from interleave_convolutional import *\n","# from features import dataset_utils # FIXME this is what this originally was\n","from dataset_utils import *\n","from gan_models import *\n","from misc import *\n","import pandas as pd"],"metadata":{"id":"BtQCZLezGNV6","executionInfo":{"status":"ok","timestamp":1701890778818,"user_tz":300,"elapsed":4348,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from tensorflow.python.framework.ops import disable_eager_execution\n","disable_eager_execution()"],"metadata":{"id":"EPMtdtoTbkuu","executionInfo":{"status":"ok","timestamp":1701890778818,"user_tz":300,"elapsed":3,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtG9NS6zL9sE","executionInfo":{"status":"ok","timestamp":1701890803029,"user_tz":300,"elapsed":24214,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}},"outputId":"6cb464be-53cf-4f30-c021-96d3c97817eb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Motivation"],"metadata":{"id":"8Q-M1OpmGOgX"}},{"cell_type":"markdown","source":["Train a GAN model to synthesize PCG audio. This means both training the discriminator and generator"],"metadata":{"id":"ASgjpyAmGQaV"}},{"cell_type":"markdown","source":["# Training Configuration"],"metadata":{"id":"BMxHySP7Ni-7"}},{"cell_type":"code","source":["# Code to do WGAN-GP training\n","# NOTE: don't attempt to run this in 'dft' or 'dct' configuration without changing the data loading method,\n","#   unless you have a lot of RAM (something like >= 24GB); as the method used to compute the transforms are\n","#   rather inefficient memory-wise for the sake of speed\n","\n","\n","# ---------------------------------------------------------------------------------------------------------------------\n","# Training Configuration\n","#   DATASET_PATTERN: glob pattern for all .wav files to train on\n","#   OUT_DIR: output directory, will contain the following files:\n","#       model_g.h5 - the saved generator model weights (note that only the weights are saved)\n","#       model_d.h5 - the saved discriminator model weights (note that only the weights are saved)\n","#       normalization.npy - normalization factors that should be divided element-wise with generator output before\n","#           synthesizing the output audio\n","#   DATA_REPR: data representation to use\n","#       'dft' for DFT images, 'dct' for DCT images, anything else for raw waveform\n","#   USE_IL: use ILConv in the generator; automatically is true for raw waveform representation\n","#   BIAS_OUT: use bias at the last layer of the generator\n","#   G_OPTIM: generator optimizer, defaults to keras.optimizers.Adam(0.0001, beta_1=0.5, beta_2=0.9)\n","#   D_OPTIM: discriminator optimizer, defaults to keras.optimizers.Adam(0.0001, beta_1=0.5, beta_2=0.9)\n","#   D_STEPS_PER_G: number of iterations to train the discriminator per iteration of generator training, must be >= 1\n","# ---------------------------------------------------------------------------------------------------------------------\n","DATASET_PATTERN = '/content/drive/MyDrive/Stuff I Coded/PCG_synthesis/data/train/*.wav'\n","OUT_DIR = '/content/drive/MyDrive/Stuff I Coded/PCG_synthesis/out'\n","DATA_REPR = 'dft'\n","USE_IL = True\n","BIAS_OUT = True\n","BATCH_SIZE = 64\n","MODEL_SIZE = 64\n","NUM_LATENT = 100\n","NUM_EPOCH_PER_CHECKPOINT = 50\n","NUM_EPOCH = 150\n","G_OPTIM = None\n","D_OPTIM = None\n","D_STEPS_PER_G = 5\n","MURMUR_TYPE = \"present\"\n","DATA_KEY_DIR = '/content/drive/MyDrive/Stuff I Coded/PCG_synthesis/data/circor_digiscope_by_pcg.csv'"],"metadata":{"id":"7dqzop8SNlL4","executionInfo":{"status":"ok","timestamp":1701890803029,"user_tz":300,"elapsed":2,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# change these to load in from a different save location!\n","FROM_CHECKPOINT = True\n","START_EPOCH = 301\n","G_CHECKPOINT = \"/content/drive/MyDrive/Stuff I Coded/PCG_synthesis/out/model_g_present_300.h5\"\n","D_CHECKPOINT = \"/content/drive/MyDrive/Stuff I Coded/PCG_synthesis/out/model_d_present_300.h5\""],"metadata":{"id":"INg0dX21ekQS","executionInfo":{"status":"ok","timestamp":1701890803029,"user_tz":300,"elapsed":2,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# reading in data key so we have access to murmur labels for the\n","# audio samples we feed into the mode\n","data_key_df = pd.read_csv(DATA_KEY_DIR)\n","train_data_key_df = data_key_df[data_key_df['split']=='TRAIN']"],"metadata":{"id":"dtCZgXxXVNnk","executionInfo":{"status":"ok","timestamp":1701890806412,"user_tz":300,"elapsed":3384,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["datalist = glob.glob(DATASET_PATTERN)\n","data = read_wav_dataset_maximal(datalist, train_data_key_df, MURMUR_TYPE)\n","num_samples = data.shape[0]"],"metadata":{"id":"riGRgQUwmQ7Q","executionInfo":{"status":"ok","timestamp":1701890875593,"user_tz":300,"elapsed":50989,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["num_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_4JSvQimRuy","executionInfo":{"status":"ok","timestamp":1701890875594,"user_tz":300,"elapsed":18,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}},"outputId":"92fffdba-9cdf-4937-fef5-432ddd9b18d5"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1723"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNu40sbYGHq9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701738035890,"user_tz":300,"elapsed":3769753,"user":{"displayName":"Daniel Chung","userId":"09947058025944665614"}},"outputId":"f87cd906-0af6-4c4f-849a-49bb07c3744e"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1723, 16384)\n","(1723, 129, 129)\n","Epoch range is 301 to 450\n","Epoch 301:\n","\t D loss: -1.564926, grad penalty: 0.147067\n","\t G loss: 0.113591\n","Epoch 302:\n","\t D loss: -1.805019, grad penalty: 0.093843\n","\t G loss: 0.097436\n","Epoch 303:\n","\t D loss: -1.271383, grad penalty: 0.105606\n","\t G loss: 0.151496\n","Epoch 304:\n","\t D loss: -1.270061, grad penalty: 0.097404\n","\t G loss: 0.163782\n","Epoch 305:\n","\t D loss: -1.796400, grad penalty: 0.188675\n","\t G loss: 0.087375\n","Epoch 306:\n","\t D loss: -1.177656, grad penalty: 0.059557\n","\t G loss: 0.228623\n","Epoch 307:\n","\t D loss: -1.984288, grad penalty: 0.193827\n","\t G loss: 0.044280\n","Epoch 308:\n","\t D loss: -1.325083, grad penalty: 0.113986\n","\t G loss: 0.024674\n","Epoch 309:\n","\t D loss: -1.108460, grad penalty: 0.109796\n","\t G loss: 0.170303\n","Epoch 310:\n","\t D loss: -1.221710, grad penalty: 0.128915\n","\t G loss: 0.196620\n","Epoch 311:\n","\t D loss: -1.395240, grad penalty: 0.138338\n","\t G loss: 0.220349\n","Epoch 312:\n","\t D loss: -1.318771, grad penalty: 0.108767\n","\t G loss: 0.076629\n","Epoch 313:\n","\t D loss: -1.555609, grad penalty: 0.217310\n","\t G loss: 0.143270\n","Epoch 314:\n","\t D loss: -1.235431, grad penalty: 0.145252\n","\t G loss: 0.198906\n","Epoch 315:\n","\t D loss: -1.368137, grad penalty: 0.088396\n","\t G loss: 0.183196\n","Epoch 316:\n","\t D loss: -1.654940, grad penalty: 0.163140\n","\t G loss: 0.140592\n","Epoch 317:\n","\t D loss: -1.406271, grad penalty: 0.145900\n","\t G loss: 0.285881\n","Epoch 318:\n","\t D loss: -1.409579, grad penalty: 0.149787\n","\t G loss: 0.123163\n","Epoch 319:\n","\t D loss: -1.118794, grad penalty: 0.095019\n","\t G loss: 0.171144\n","Epoch 320:\n","\t D loss: -1.343692, grad penalty: 0.071334\n","\t G loss: 0.174777\n","Epoch 321:\n","\t D loss: -1.484398, grad penalty: 0.221673\n","\t G loss: 0.195265\n","Epoch 322:\n","\t D loss: -1.423143, grad penalty: 0.102961\n","\t G loss: 0.308445\n","Epoch 323:\n","\t D loss: -0.973333, grad penalty: 0.124797\n","\t G loss: 0.208557\n","Epoch 324:\n","\t D loss: -1.166428, grad penalty: 0.049331\n","\t G loss: 0.279974\n","Epoch 325:\n","\t D loss: -1.411561, grad penalty: 0.168378\n","\t G loss: 0.172987\n","Epoch 326:\n","\t D loss: -1.313248, grad penalty: 0.177462\n","\t G loss: 0.196687\n","Epoch 327:\n","\t D loss: -1.539722, grad penalty: 0.137045\n","\t G loss: 0.055825\n","Epoch 328:\n","\t D loss: -1.074746, grad penalty: 0.111976\n","\t G loss: 0.112911\n","Epoch 329:\n","\t D loss: -1.435830, grad penalty: 0.204628\n","\t G loss: 0.223963\n","Epoch 330:\n","\t D loss: -1.250047, grad penalty: 0.158598\n","\t G loss: 0.160305\n","Epoch 331:\n","\t D loss: -1.478894, grad penalty: 0.123184\n","\t G loss: 0.035272\n","Epoch 332:\n","\t D loss: -1.260215, grad penalty: 0.108440\n","\t G loss: 0.091290\n","Epoch 333:\n","\t D loss: -0.924835, grad penalty: 0.128576\n","\t G loss: 0.157748\n","Epoch 334:\n","\t D loss: -1.689542, grad penalty: 0.155041\n","\t G loss: 0.187531\n","Epoch 335:\n","\t D loss: -1.347001, grad penalty: 0.122579\n","\t G loss: 0.096381\n","Epoch 336:\n","\t D loss: -1.091427, grad penalty: 0.092066\n","\t G loss: 0.245485\n","Epoch 337:\n","\t D loss: -1.698812, grad penalty: 0.248628\n","\t G loss: 0.175930\n","Epoch 338:\n","\t D loss: -1.549502, grad penalty: 0.260072\n","\t G loss: 0.270433\n","Epoch 339:\n","\t D loss: -1.389615, grad penalty: 0.165411\n","\t G loss: 0.149846\n","Epoch 340:\n","\t D loss: -1.257995, grad penalty: 0.139974\n","\t G loss: 0.212333\n","Epoch 341:\n","\t D loss: -1.423758, grad penalty: 0.141483\n","\t G loss: 0.216382\n","Epoch 342:\n","\t D loss: -1.469024, grad penalty: 0.154095\n","\t G loss: 0.152706\n","Epoch 343:\n","\t D loss: -1.395786, grad penalty: 0.219026\n","\t G loss: 0.190815\n","Epoch 344:\n","\t D loss: -1.468545, grad penalty: 0.134341\n","\t G loss: 0.168588\n","Epoch 345:\n","\t D loss: -1.354261, grad penalty: 0.158505\n","\t G loss: 0.217105\n","Epoch 346:\n","\t D loss: -1.558784, grad penalty: 0.215699\n","\t G loss: 0.133703\n","Epoch 347:\n","\t D loss: -1.323710, grad penalty: 0.131847\n","\t G loss: 0.239511\n","Epoch 348:\n","\t D loss: -1.291935, grad penalty: 0.160611\n","\t G loss: 0.157555\n","Epoch 349:\n","\t D loss: -1.566674, grad penalty: 0.108339\n","\t G loss: 0.159244\n","Epoch 350:\n","\t D loss: -1.220872, grad penalty: 0.109170\n","\t G loss: 0.224855\n","Checkpoint Saved\n","Epoch 351:\n","\t D loss: -1.634547, grad penalty: 0.185375\n","\t G loss: 0.179953\n","Epoch 352:\n","\t D loss: -1.252619, grad penalty: 0.140954\n","\t G loss: 0.241076\n","Epoch 353:\n","\t D loss: -1.293252, grad penalty: 0.140755\n","\t G loss: 0.152525\n","Epoch 354:\n","\t D loss: -1.230775, grad penalty: 0.141704\n","\t G loss: 0.284155\n","Epoch 355:\n","\t D loss: -1.237048, grad penalty: 0.100989\n","\t G loss: 0.201553\n","Epoch 356:\n","\t D loss: -1.482504, grad penalty: 0.161124\n","\t G loss: 0.167470\n","Epoch 357:\n","\t D loss: -1.474299, grad penalty: 0.155872\n","\t G loss: 0.176137\n","Epoch 358:\n","\t D loss: -1.183578, grad penalty: 0.077236\n","\t G loss: 0.109055\n","Epoch 359:\n","\t D loss: -0.960657, grad penalty: 0.039981\n","\t G loss: 0.158398\n","Epoch 360:\n","\t D loss: -1.625403, grad penalty: 0.248467\n","\t G loss: 0.118028\n","Epoch 361:\n","\t D loss: -1.664031, grad penalty: 0.130866\n","\t G loss: 0.115929\n","Epoch 362:\n","\t D loss: -1.323870, grad penalty: 0.103652\n","\t G loss: 0.119027\n","Epoch 363:\n","\t D loss: -1.181675, grad penalty: 0.105891\n","\t G loss: 0.109008\n","Epoch 364:\n","\t D loss: -1.479912, grad penalty: 0.130328\n","\t G loss: 0.097799\n","Epoch 365:\n","\t D loss: -1.082169, grad penalty: 0.088851\n","\t G loss: 0.205608\n","Epoch 366:\n","\t D loss: -1.588027, grad penalty: 0.233232\n","\t G loss: 0.150167\n","Epoch 367:\n","\t D loss: -1.170310, grad penalty: 0.121379\n","\t G loss: 0.185130\n","Epoch 368:\n","\t D loss: -1.471511, grad penalty: 0.162733\n","\t G loss: 0.180282\n","Epoch 369:\n","\t D loss: -1.644749, grad penalty: 0.313604\n","\t G loss: 0.166642\n","Epoch 370:\n","\t D loss: -1.187486, grad penalty: 0.055331\n","\t G loss: 0.200769\n","Epoch 371:\n","\t D loss: -1.120106, grad penalty: 0.072005\n","\t G loss: 0.203801\n","Epoch 372:\n","\t D loss: -1.393522, grad penalty: 0.129618\n","\t G loss: 0.242927\n","Epoch 373:\n","\t D loss: -1.688611, grad penalty: 0.200068\n","\t G loss: 0.215302\n","Epoch 374:\n","\t D loss: -1.349136, grad penalty: 0.127698\n","\t G loss: 0.088455\n","Epoch 375:\n","\t D loss: -1.429849, grad penalty: 0.161082\n","\t G loss: 0.093391\n","Epoch 376:\n","\t D loss: -1.536723, grad penalty: 0.179229\n","\t G loss: 0.149367\n","Epoch 377:\n","\t D loss: -1.482475, grad penalty: 0.091738\n","\t G loss: 0.084433\n","Epoch 378:\n","\t D loss: -1.444704, grad penalty: 0.113332\n","\t G loss: 0.077841\n","Epoch 379:\n","\t D loss: -1.499176, grad penalty: 0.152619\n","\t G loss: 0.121854\n","Epoch 380:\n","\t D loss: -2.018674, grad penalty: 0.160663\n","\t G loss: 0.059300\n","Epoch 381:\n","\t D loss: -1.280954, grad penalty: 0.106307\n","\t G loss: 0.170952\n","Epoch 382:\n","\t D loss: -1.557458, grad penalty: 0.133918\n","\t G loss: 0.132098\n","Epoch 383:\n","\t D loss: -1.493709, grad penalty: 0.136792\n","\t G loss: 0.228935\n","Epoch 384:\n","\t D loss: -1.107605, grad penalty: 0.151346\n","\t G loss: 0.188474\n","Epoch 385:\n","\t D loss: -1.120528, grad penalty: 0.076679\n","\t G loss: 0.152693\n","Epoch 386:\n","\t D loss: -1.286064, grad penalty: 0.089388\n","\t G loss: 0.097196\n","Epoch 387:\n","\t D loss: -1.497177, grad penalty: 0.127762\n","\t G loss: 0.141166\n","Epoch 388:\n","\t D loss: -1.342458, grad penalty: 0.129808\n","\t G loss: 0.093839\n","Epoch 389:\n","\t D loss: -1.015193, grad penalty: 0.093121\n","\t G loss: 0.114837\n","Epoch 390:\n","\t D loss: -1.813025, grad penalty: 0.155569\n","\t G loss: -0.029230\n","Epoch 391:\n","\t D loss: -1.535023, grad penalty: 0.186655\n","\t G loss: 0.067817\n","Epoch 392:\n","\t D loss: -1.437323, grad penalty: 0.197707\n","\t G loss: 0.222165\n","Epoch 393:\n","\t D loss: -1.892139, grad penalty: 0.250089\n","\t G loss: 0.174356\n","Epoch 394:\n","\t D loss: -1.369220, grad penalty: 0.099536\n","\t G loss: 0.089727\n","Epoch 395:\n","\t D loss: -1.134219, grad penalty: 0.119901\n","\t G loss: 0.133111\n","Epoch 396:\n","\t D loss: -1.326137, grad penalty: 0.149042\n","\t G loss: 0.210404\n","Epoch 397:\n","\t D loss: -1.260242, grad penalty: 0.139929\n","\t G loss: 0.199834\n","Epoch 398:\n","\t D loss: -1.522459, grad penalty: 0.188304\n","\t G loss: 0.123325\n","Epoch 399:\n","\t D loss: -1.029866, grad penalty: 0.141216\n","\t G loss: 0.264341\n","Epoch 400:\n","\t D loss: -1.336419, grad penalty: 0.154849\n","\t G loss: 0.206170\n","Checkpoint Saved\n","Epoch 401:\n","\t D loss: -1.562900, grad penalty: 0.154779\n","\t G loss: 0.058418\n","Epoch 402:\n","\t D loss: -1.362668, grad penalty: 0.232852\n","\t G loss: 0.224849\n","Epoch 403:\n","\t D loss: -1.247040, grad penalty: 0.051969\n","\t G loss: 0.244948\n","Epoch 404:\n","\t D loss: -1.343059, grad penalty: 0.103761\n","\t G loss: 0.143644\n","Epoch 405:\n","\t D loss: -1.726236, grad penalty: 0.196473\n","\t G loss: 0.182019\n","Epoch 406:\n","\t D loss: -1.496302, grad penalty: 0.154166\n","\t G loss: 0.118364\n","Epoch 407:\n","\t D loss: -1.629730, grad penalty: 0.214365\n","\t G loss: 0.186546\n","Epoch 408:\n","\t D loss: -1.436471, grad penalty: 0.171282\n","\t G loss: 0.305982\n","Epoch 409:\n","\t D loss: -1.195624, grad penalty: 0.105814\n","\t G loss: 0.135530\n","Epoch 410:\n","\t D loss: -0.956639, grad penalty: 0.122850\n","\t G loss: 0.203991\n","Epoch 411:\n","\t D loss: -1.225910, grad penalty: 0.094832\n","\t G loss: 0.162865\n","Epoch 412:\n","\t D loss: -1.421607, grad penalty: 0.086009\n","\t G loss: 0.123675\n","Epoch 413:\n","\t D loss: -1.110113, grad penalty: 0.094444\n","\t G loss: 0.301111\n","Epoch 414:\n","\t D loss: -1.574130, grad penalty: 0.152054\n","\t G loss: 0.079423\n","Epoch 415:\n","\t D loss: -1.243494, grad penalty: 0.076397\n","\t G loss: 0.191299\n","Epoch 416:\n","\t D loss: -1.665889, grad penalty: 0.144408\n","\t G loss: 0.152898\n","Epoch 417:\n","\t D loss: -0.849351, grad penalty: 0.080643\n","\t G loss: 0.242170\n","Epoch 418:\n","\t D loss: -1.652168, grad penalty: 0.233886\n","\t G loss: 0.147536\n","Epoch 419:\n","\t D loss: -1.582061, grad penalty: 0.158497\n","\t G loss: 0.190494\n","Epoch 420:\n","\t D loss: -1.549469, grad penalty: 0.149562\n","\t G loss: 0.107009\n","Epoch 421:\n","\t D loss: -1.314080, grad penalty: 0.102293\n","\t G loss: 0.046177\n","Epoch 422:\n","\t D loss: -1.372419, grad penalty: 0.109197\n","\t G loss: 0.317521\n","Epoch 423:\n","\t D loss: -1.553289, grad penalty: 0.115205\n","\t G loss: 0.196388\n","Epoch 424:\n","\t D loss: -0.916458, grad penalty: 0.126780\n","\t G loss: 0.389102\n","Epoch 425:\n","\t D loss: -0.945009, grad penalty: 0.107543\n","\t G loss: 0.231376\n","Epoch 426:\n","\t D loss: -1.624096, grad penalty: 0.271988\n","\t G loss: 0.180143\n","Epoch 427:\n","\t D loss: -1.179239, grad penalty: 0.130881\n","\t G loss: 0.210761\n","Epoch 428:\n","\t D loss: -1.097804, grad penalty: 0.082252\n","\t G loss: 0.280537\n","Epoch 429:\n","\t D loss: -1.310215, grad penalty: 0.092330\n","\t G loss: 0.319071\n","Epoch 430:\n","\t D loss: -1.410313, grad penalty: 0.158149\n","\t G loss: 0.176723\n","Epoch 431:\n","\t D loss: -1.628130, grad penalty: 0.150559\n","\t G loss: 0.159023\n","Epoch 432:\n","\t D loss: -1.401011, grad penalty: 0.120123\n","\t G loss: 0.219923\n","Epoch 433:\n","\t D loss: -1.566307, grad penalty: 0.182546\n","\t G loss: 0.205852\n","Epoch 434:\n","\t D loss: -1.514152, grad penalty: 0.145332\n","\t G loss: 0.154099\n","Epoch 435:\n","\t D loss: -1.278795, grad penalty: 0.162691\n","\t G loss: 0.179569\n","Epoch 436:\n","\t D loss: -1.244479, grad penalty: 0.123686\n","\t G loss: 0.210502\n","Epoch 437:\n","\t D loss: -1.525670, grad penalty: 0.232623\n","\t G loss: 0.089281\n","Epoch 438:\n","\t D loss: -1.247063, grad penalty: 0.076251\n","\t G loss: 0.143676\n","Epoch 439:\n","\t D loss: -1.133838, grad penalty: 0.214079\n","\t G loss: 0.123962\n","Epoch 440:\n","\t D loss: -1.164740, grad penalty: 0.080550\n","\t G loss: 0.202525\n","Epoch 441:\n","\t D loss: -1.331423, grad penalty: 0.096080\n","\t G loss: 0.047162\n","Epoch 442:\n","\t D loss: -1.336567, grad penalty: 0.133190\n","\t G loss: 0.193378\n","Epoch 443:\n","\t D loss: -0.972020, grad penalty: 0.066981\n","\t G loss: 0.195127\n","Epoch 444:\n","\t D loss: -1.327161, grad penalty: 0.197271\n","\t G loss: 0.161182\n","Epoch 445:\n","\t D loss: -1.297609, grad penalty: 0.147793\n","\t G loss: 0.361986\n","Epoch 446:\n","\t D loss: -1.307506, grad penalty: 0.106640\n","\t G loss: 0.412951\n","Epoch 447:\n","\t D loss: -1.354380, grad penalty: 0.124716\n","\t G loss: 0.201336\n","Epoch 448:\n","\t D loss: -1.069074, grad penalty: 0.083291\n","\t G loss: 0.274579\n","Epoch 449:\n","\t D loss: -1.169030, grad penalty: 0.196904\n","\t G loss: 0.210427\n","Epoch 450:\n","\t D loss: -1.603007, grad penalty: 0.190599\n","\t G loss: 0.172224\n","Checkpoint Saved\n"]}],"source":["# 'labels' used to apply in computing the Wasserstein loss\n","positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n","negative_y = -positive_y\n","dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32) # need to feed in some labels for gradient penalty loss\n","\n","# create and build model\n","if (DATA_REPR == 'dft'):\n","    gen_func = dft_generator if USE_IL else dft_generator_tr\n","    disc_func = dft_discriminator\n","elif (DATA_REPR == 'dct'):\n","    gen_func = dct_generator if USE_IL else dct_generator_tr\n","    disc_func = dct_discriminator\n","else:\n","    gen_func = wave_generator\n","    disc_func = wave_discriminator\n","generator = gen_func(MODEL_SIZE, NUM_LATENT, BIAS_OUT)\n","discriminator = disc_func(MODEL_SIZE)\n","\n","if FROM_CHECKPOINT:\n","    generator.load_weights(G_CHECKPOINT)\n","    discriminator.load_weights(D_CHECKPOINT)\n","\n","g_m, d_m = create_wgan(generator, discriminator)\n","\n","# read in dataset and transform it appropriately\n","datalist = glob.glob(DATASET_PATTERN)\n","data = read_wav_dataset_maximal(datalist, train_data_key_df, MURMUR_TYPE)\n","num_samples = data.shape[0]\n","if (DATA_REPR == 'dft'):\n","    data = dft_transform_forward(data)\n","elif (DATA_REPR == 'dct'):\n","    data = dct_transform_forward(data)\n","else:\n","    data = np.expand_dims(data, axis=-1)\n","\n","# normalize data\n","if (DATA_REPR == 'dft' or DATA_REPR == 'dct'):\n","    if (DATA_REPR == 'dft'):\n","        data_mag = np.abs(data[:,:,:,0:1] + 1j * data[:,:,:,1:2])\n","    else:\n","        data_mag = np.abs(data)\n","    amp_max = np.max(data_mag, axis=(0,-2,-1), keepdims=True)\n","    norm_f = 0.9/amp_max\n","else:\n","    norm_f = 1.0\n","np.save(os.path.join(OUT_DIR, 'normalization.npy'), norm_f)\n","\n","# running tallies\n","epochs = []\n","d_losses = []\n","grad_penalties = []\n","g_losses = []\n","\n","# begin training\n","model_path_g = os.path.join(OUT_DIR, 'model_g_{}_{:d}.h5')\n","model_path_d = os.path.join(OUT_DIR, 'model_d_{}_{:d}.h5')\n","idx = np.arange(num_samples)\n","print(f\"Epoch range is {START_EPOCH} to {START_EPOCH + NUM_EPOCH - 1}\")\n","for epoch_i in range((START_EPOCH * D_STEPS_PER_G), ((START_EPOCH + NUM_EPOCH) * D_STEPS_PER_G)):\n","    np.random.shuffle(idx)\n","    for superbatch_i in range(0, num_samples // (BATCH_SIZE * D_STEPS_PER_G)):\n","        batch_idx = idx[(superbatch_i*BATCH_SIZE*D_STEPS_PER_G):((superbatch_i+1)*BATCH_SIZE*D_STEPS_PER_G)]\n","        # train discriminator\n","        for batch_i in range(0, D_STEPS_PER_G):\n","            real = data[batch_idx[(batch_i*BATCH_SIZE):((batch_i+1)*BATCH_SIZE)],...] * norm_f\n","            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, NUM_LATENT)).astype(np.float32)\n","            d_loss = d_m.train_on_batch([real, noise], [positive_y, negative_y, dummy_y])\n","        # train generator\n","        noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, NUM_LATENT)).astype(np.float32)\n","        g_loss = g_m.train_on_batch(noise, positive_y)\n","\n","    if (epoch_i % D_STEPS_PER_G == 0):\n","        print('Epoch {:d}:'.format(epoch_i // D_STEPS_PER_G))\n","        print('\\t D loss: {:f}, grad penalty: {:f}'.format(d_loss[1]+d_loss[2], d_loss[3]))\n","        print('\\t G loss: {:f}'.format(g_loss), flush=True)\n","\n","        # record losses each epoch\n","        epochs.append(epoch_i // D_STEPS_PER_G)\n","        d_losses.append(d_loss[1]+d_loss[2])\n","        grad_penalties.append(d_loss[3])\n","        g_losses.append(g_loss)\n","\n","        # save model weights if this is a checkpoint epoch\n","        if ((epoch_i // D_STEPS_PER_G) % NUM_EPOCH_PER_CHECKPOINT == 0):\n","            generator.save_weights(model_path_g.format(MURMUR_TYPE, epoch_i // D_STEPS_PER_G))\n","            discriminator.save_weights(model_path_d.format(MURMUR_TYPE, epoch_i // D_STEPS_PER_G))\n","\n","            losses_df = pd.DataFrame({'epoch': epochs, 'd_loss': d_losses, 'grad_penalty': grad_penalties, 'g_loss': g_losses})\n","            losses_df.to_csv(os.path.join(OUT_DIR, f\"losses_epochs{(epoch_i // D_STEPS_PER_G)-NUM_EPOCH_PER_CHECKPOINT}_to_{(epoch_i // D_STEPS_PER_G)}.csv\"))\n","            print(\"Checkpoint Saved\")\n","            epochs = []\n","            d_losses = []\n","            grad_penalties = []\n","            g_losses = []\n","\n","# save final model weights\n","generator.save_weights(model_path_g.format(MURMUR_TYPE, NUM_EPOCH))\n","discriminator.save_weights(model_path_d.format(MURMUR_TYPE, NUM_EPOCH))\n"]},{"cell_type":"code","source":["# automatically disconnect runtime after training\n","# (avoids wasting compute units)\n","from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"erEZL3-_Rac_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oCyus_xk9-kB"},"execution_count":null,"outputs":[]}]}